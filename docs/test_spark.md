# Prueba de funcionamiento de Apache Spark

Este documento describe una prueba b치sica para verificar que el cl칰ster de
**Apache Spark** ejecut치ndose en **Docker** funciona correctamente y acepta
trabajos enviados desde Python (PyCharm).

---

## 游꿢 Objetivo de la prueba

- Comprobar que PyCharm puede conectarse al Spark Master.
- Validar que Spark ejecuta un job distribuido.
- Confirmar que la comunicaci칩n se realiza por el puerto `7077`.

---

## 游빔 Entorno de ejecuci칩n

- Sistema operativo: Windows
- Entorno Big Data: Docker + Apache Spark
- Cliente: Python (PyCharm)
- Configuraci칩n del cl칰ster:
  - 1 Spark Master
  - 1 Spark Worker (2GB RAM)

---

## 郊윒잺 Ejecuci칩n de la prueba

1. El cl칰ster Spark debe estar arrancado:
   ```bash
   docker compose up -d
## Requisitos
2. Instalar librer칤asWindows 10/11
- (Para la prueba) `pyspark` en tu entorno local:
  ```bash
  pip install pyspark
### Ejecuci칩n desde terminal (opcional)
2. Ejecutar script

![img](images/containers.png)

![img](images/spark-master.png)

Ejecutamos en el contenedor spark master

    ls /opt/bitnami/spark/scripts
    test_spark.py
    spark-submit \
      --master spark://spark-master:7077 \
      /opt/bitnami/spark/scripts/test_spark.py

![img](images/example.png)






